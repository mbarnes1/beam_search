{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from beam import BeamSearch\n",
    "from functools import partial\n",
    "from itertools import izip, repeat\n",
    "import sys\n",
    "import time\n",
    "sys.path.append('../coco-caption')\n",
    "sys.path.append('../show-attend-and-tell-tensorflow')\n",
    "from core.utils import load_pickle\n",
    "from pycocoevalcap.bleu.bleu import Bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ../show-attend-and-tell-tensorflow/data/train/word_to_idx.pkl..\n",
      "Loaded ../show-attend-and-tell-tensorflow/data/train/train.references.pkl..\n"
     ]
    }
   ],
   "source": [
    "split = 'train'\n",
    "word_to_idx = load_pickle('../show-attend-and-tell-tensorflow/data/train/word_to_idx.pkl')\n",
    "words = word_to_idx.keys()\n",
    "words.remove('<START>')\n",
    "words.remove('<END>')\n",
    "words.remove('<NULL>')\n",
    "words.append('.')\n",
    "references = load_pickle('../show-attend-and-tell-tensorflow/data/{}/{}.references.pkl'.format(split, split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scorer = Bleu(n=4)\n",
    "\n",
    "def score(hypotheses, reference_sequences):\n",
    "    \"\"\"\n",
    "    Score each hypothesis. Any sequence in reference_sequences is correct.\n",
    "    Returns the best score for each hypothesis, among the reference_sequences.\n",
    "    :param hypotheses: Dict of hypotheses to compute score.\n",
    "    :param reference_sequences: List of ground truth sequences.\n",
    "    :return scores: Dict with same keys as hypotheses, but with score as value\n",
    "    \"\"\"\n",
    "    #hypotheses = dict(izip(xrange(0, len(hypotheses)), hypotheses))\n",
    "    reference_sequences = dict(izip(hypotheses.iterkeys(), repeat(reference_sequences, len(hypotheses))))\n",
    "    _, scores = scorer.compute_score(reference_sequences, hypotheses)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search\n",
    "#### with reference actions\n",
    "Reference words are as good, or better than, non-reference words in terms of BLEU score. Only a handful (~50) reference words to consider, but potentially 10k+ non-reference words. So by only considering the reference words as the set of actions available to expert, beam search is dramatically faster.\n",
    "< 1s per search with reference word actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b8a7eb4ca94d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscore_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbeam_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeamSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mbarnes1/Documents/trafficjam/aggrevated/beam_search/beam.pyc\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, max_length)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mnew_beams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbeam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mnew_beams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mizip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_beams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_beams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_beams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Sort to get best beams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-428434720719>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(hypotheses, reference_sequences)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#hypotheses = dict(izip(xrange(0, len(hypotheses)), hypotheses))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mreference_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mizip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypotheses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mbarnes1/Documents/trafficjam/aggrevated/coco-caption/pycocoevalcap/bleu/bleu.pyc\u001b[0m in \u001b[0;36mcompute_score\u001b[0;34m(self, gts, res)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "n_beams = 5\n",
    "n_searches = 2\n",
    "for counter, (_, reference) in enumerate(references.iteritems()):\n",
    "    if counter >= n_searches:\n",
    "        break\n",
    "\n",
    "    print 'Ground truth:\\n \\t', '\\n \\t'.join(reference)\n",
    "    score_wrapper = partial(score, reference_sequences=reference)\n",
    "    reference_words = set()\n",
    "    for sentence in reference:\n",
    "        reference_words.update(sentence.split(' '))\n",
    "    beam_search = BeamSearch(n_beams, score_wrapper, reference_words)\n",
    "    initial_beams = [[sentence.split(' ')[0]] for sentence in reference]\n",
    "    scores, sequence = beam_search.search(max_length=15, beams=initial_beams)\n",
    "\n",
    "end_time = time.time()\n",
    "print ' \\n Elapsed time per search: {}s \\n \\n'.format(float(end_time - start_time) / n_searches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with all actions\n",
    "< 1s per search with reference word actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "n_beams = 5\n",
    "n_searches = 2\n",
    "for counter, (_, reference) in enumerate(references.iteritems()):\n",
    "    if counter >= n_searches:\n",
    "        break\n",
    "\n",
    "    print 'Ground truth:\\n \\t', '\\n \\t'.join(reference)\n",
    "    score_wrapper = partial(score, reference_sequences=reference)\n",
    "    beam_search = BeamSearch(n_beams, score_wrapper, words)\n",
    "    initial_beams = [[sentence.split(' ')[0]] for sentence in reference]\n",
    "    scores, sequence = beam_search.search(max_length=15, beams=initial_beams)\n",
    "\n",
    "end_time = time.time()\n",
    "print ' \\n Elapsed time per search: {}s \\n \\n'.format(float(end_time - start_time) / n_searches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
